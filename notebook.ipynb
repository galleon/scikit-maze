{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IKyurnIXMOd_"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVce05OPBOeD",
    "outputId": "6857831b-f00f-48ff-a71a-b410b47c6cbf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab'in sys.modules:\n",
    "    !pip install scikit-decide[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ux_OarNsKvtq",
    "outputId": "276fbeba-764e-4866-ded1-80fe048c6ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'scikit-maze'...\n",
      "remote: Enumerating objects: 99, done.\u001b[K\n",
      "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
      "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
      "remote: Total 99 (delta 40), reused 80 (delta 21), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (99/99), done.\n"
     ]
    }
   ],
   "source": [
    "!(rm -rf scikit-maze/; git clone https://github.com/galleon/scikit-maze.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZQFxdDmxLO0I"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,'./scikit-maze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AxcQEPf6BVXS"
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Any, List, NamedTuple, Optional\n",
    "\n",
    "from skdecide import DeterministicPlanningDomain, Space, Value\n",
    "from skdecide.builders.domain import UnrestrictedActions, Renderable\n",
    "from skdecide.utils import rollout, match_solvers, load_registered_solver\n",
    "from skdecide.hub.space.gym import ListSpace, EnumSpace, MultiDiscreteSpace\n",
    "from skdecide.hub.solver.lazy_astar import LazyAstar\n",
    "\n",
    "from utils import Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buff = io.BytesIO()\n",
    "#img = Image.fromarray(im_array)\n",
    "#img.save(buff, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets.Image(value=buff.getvalue(), format='png', layout=widgets.Layout(width='200px'))\n",
    "#widgets.Image(value=buff.getvalue(), layout=widgets.Layout(width='200px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Action & State spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(NamedTuple):\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "class Action(Enum):\n",
    "    up = 0\n",
    "    down = 1\n",
    "    left = 2\n",
    "    right = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a base domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(DeterministicPlanningDomain, UnrestrictedActions, Renderable):\n",
    "    T_state = State  # Type of states\n",
    "    T_observation = T_state  # Type of observations\n",
    "    T_event = Action  # Type of events\n",
    "    T_value = float  # Type of transition values (rewards or costs)\n",
    "    T_predicate = bool  # Type of logical checks\n",
    "    T_info = None  # Type of additional information in environment outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the maze domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "class MazeDomain(D):\n",
    "\n",
    "    def __init__(self, start, end, maze, image_widget=None):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.maze = maze\n",
    "        self.image_widget = image_widget\n",
    "        #if self.image_widget:\n",
    "        #    self.image_widget.layout = widgets.Layout(width='200px')\n",
    "\n",
    "    def _get_next_state(self, memory: D.T_state, action: D.T_event) -> D.T_state:\n",
    "        # Move agent according to action (except if bumping into a wall)\n",
    "        next_x, next_y = memory.x, memory.y\n",
    "        if action == Action.up:\n",
    "            next_x -= 1\n",
    "        if action == Action.down:\n",
    "            next_x += 1\n",
    "        if action == Action.left:\n",
    "            next_y -= 1\n",
    "        if action == Action.right:\n",
    "            next_y += 1\n",
    "        return State(next_x, next_y) if self.maze.is_an_empty_cell(next_x, next_y) else memory\n",
    "\n",
    "    def _get_transition_value(self, memory: D.T_state, action: D.T_event, next_state: Optional[D.T_state] = None) -> \\\n",
    "            Value[D.T_value]:\n",
    "        # Set cost to 1 when moving (energy cost) and to 2 when bumping into a wall (damage cost)\n",
    "        return Value(cost=1 if next_state != memory else 2)\n",
    "\n",
    "    def _get_initial_state_(self) -> D.T_state:\n",
    "        # Set the start position as initial state\n",
    "        return self.start\n",
    "\n",
    "    def _get_goals_(self) -> Space[D.T_observation]:\n",
    "        # Set the end position as goal\n",
    "        return ListSpace([self.end])\n",
    "\n",
    "    def _is_terminal(self, state: D.T_state) -> D.T_agent[D.T_predicate]:\n",
    "        # Stop an episode only when goal reached\n",
    "        return self._is_goal(state)\n",
    "\n",
    "    def _get_action_space_(self) -> Space[D.T_event]:\n",
    "        # Define action space\n",
    "        return EnumSpace(Action)\n",
    "\n",
    "    def _get_observation_space_(self) -> Space[D.T_observation]:\n",
    "        # Define observation space\n",
    "        num_rows = self.maze.height\n",
    "        num_cols = self.maze.width\n",
    "        return MultiDiscreteSpace([num_rows, num_cols])\n",
    "\n",
    "    def _render_from(self, memory: D.T_state, **kwargs: Any) -> Any:\n",
    "        # ¬†display maze in an image widget\n",
    "        #with io.BytesIO() as buff:\n",
    "        #    img = Image.fromarray(maze.get_image().repeat(4, 0).repeat(4, 1))\n",
    "        #    img.save(buff, format='png')\n",
    "        #    self.image_widget.value = buff.getvalue()\n",
    "        buff = io.BytesIO()\n",
    "        maze_ = self.maze.get_image(memory.x, memory.y).repeat(4, 0).repeat(4, 1)\n",
    "        img = Image.fromarray(maze_)\n",
    "        img.save(buff, format='png')\n",
    "        return buff.getvalue()\n",
    "        \n",
    "        \n",
    "    def heuristic(self, s: D.T_state) -> Value:\n",
    "        return Value(cost=sqrt((self.end.x - s.x)**2 + (self.end.y - s.y)**2))\n",
    "    \n",
    "    def state_features(self, s: D.T_state) -> List[float]:\n",
    "        return [s.x, s.y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 50, 50\n",
    "\n",
    "maze = Maze(width, height)\n",
    "\n",
    "domain_factory = lambda: MazeDomain(State(1, 1), State(width-2, height-2), maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render the maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b2f1a2a8ac43bd8a340db285880261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xcc\\x00\\x00\\x00\\xcc\\x08\\x00\\x00\\x00\\x00\\x1aI\\x13‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.Image(value=domain_factory()._render_from(State(1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let solve with A*\n",
    "\n",
    "Let's try to use a first solver named A. A (pronounced \"A-star\") is a graph traversal and path search algorithm, which is often used in many fields of computer science due to its completeness, optimality, and optimal efficiency.\n",
    "\n",
    "One major practical drawback is its  ùëÇ(ùëèùëë)  space complexity, as it stores all generated nodes in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b3b57d8b8440919cca037471d230fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = output = widgets.Image(format='png')\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "State(x=1, y=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106/1756867654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/skdecide/builders/solver/policy.py\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0msampled\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_observation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_concurrency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_event\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/skdecide/builders/solver/policy.py\u001b[0m in \u001b[0;36m_sample_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_observation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_concurrency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_event\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mautocastable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/skdecide/builders/solver/policy.py\u001b[0m in \u001b[0;36m_get_next_action_distribution\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    100\u001b[0m     def _get_next_action_distribution(self, observation: D.T_agent[D.T_observation]) -> Distribution[\n\u001b[1;32m    101\u001b[0m             D.T_agent[D.T_concurrency[D.T_event]]]:\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSingleValueDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mautocastable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/skdecide/hub/solver/lazy_astar/lazy_astar.py\u001b[0m in \u001b[0;36m_get_next_action\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_observation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_concurrency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_event\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_policy_defined_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_agent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_observation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: State(x=1, y=1)"
     ]
    }
   ],
   "source": [
    "domain = domain_factory()\n",
    "\n",
    "# Check that we can solve the Maze with LazyAstar\n",
    "assert LazyAstar.check_domain(domain)\n",
    "\n",
    "# All good, let's use LazyAstar\n",
    "with LazyAstar() as solver:\n",
    "    # Let's solve the domain\n",
    "    MazeDomain.solve_with(solver, domain_factory)\n",
    "    \n",
    "    # Now let's see the solution\n",
    "    for i_episode in range(1):\n",
    "        # Initialize episode\n",
    "        solver.reset()\n",
    "        observation = domain.reset()\n",
    "            \n",
    "        # Let's define maximum number of steps\n",
    "        step, max_steps = 1, 1000\n",
    "\n",
    "        while step <= max_steps:\n",
    "\n",
    "            if isinstance(domain, Renderable):\n",
    "                output.value = domain._render_from(observation)\n",
    "    \n",
    "            action = solver.sample_action(observation)\n",
    "    \n",
    "            outcome = domain.step(action)\n",
    "            observation = outcome.observation\n",
    "\n",
    "            termination = domain._is_terminal(observation)\n",
    "            if termination:\n",
    "                print(f'Episode {i_episode + 1} terminated after {step + 1} steps.')\n",
    "                break\n",
    "\n",
    "            time.sleep(wait)\n",
    "            step += 1\n",
    "        \n",
    "        if isinstance(domain, Renderable):\n",
    "            output.value = domain._render_from(observation)\n",
    "            \n",
    "        print(f'The goal was {\"\" if domain.is_goal(observation) else \" not\"} reached in episode {i_episode + 1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
